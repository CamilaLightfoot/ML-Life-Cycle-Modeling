# ML-Life-Cycle-Modeling

## Project Overview
This project is part of my eCornell Machine Learning portfolio and focuses on the **modeling stage** of the ML life cycle.  
Using the **Airbnb NYC Listings** dataset, I trained and evaluated **Decision Tree (DT)** and **K-Nearest Neighbors (KNN)** classifiers, tuning their hyperparameters to identify the best‚Äëperforming model. The lab emphasizes **feature engineering**, **model comparison**, and **evaluation metrics** to guide predictive problem‚Äësolving.

## Objectives
- Define the ML problem and prepare a feature matrix.  
- Perform one‚Äëhot encoding for categorical variables.  
- Train and optimize Decision Tree and KNN models.  
- Compare model performance and select the optimal one.  
- Interpret results and discuss considerations for deployment.

## Methodology
1. **Data Preparation** ‚Äì Feature engineering, one‚Äëhot encoding, and scaling where needed.  
2. **Model Training** ‚Äì Train DT and KNN classifiers with various hyperparameter configurations.  
3. **Evaluation** ‚Äì Measure performance using accuracy and visualizations.  
4. **Comparison** ‚Äì Analyze trade‚Äëoffs between DTs and KNNs to determine the most suitable model.  
5. **Conclusion** ‚Äì Summarize findings and the best‚Äëperforming configuration.

## üìÇ Files in this Repository
- **`CompareKNNsAndDTs.ipynb`** ‚Äì Main Jupyter Notebook with full implementation, including training, evaluation, and comparison of DTs and KNNs.  
- **`CompareKNNsAndDTs.py`** ‚Äì Script version of the notebook, containing the modeling logic for non‚Äënotebook workflows.  
- **`airbnbData_train.csv`** ‚Äì Airbnb NYC Listings training subset used for model building.

## üìä Results & Key Findings
- Both DT and KNN models were trained and tuned across multiple hyperparameters.  
- Accuracy varies with configuration; the best model (per notebook) outperforms baseline and highlights the bias‚Äìvariance trade‚Äëoff.  
- Visualizations (accuracy vs. hyperparameter) help select robust configurations and reveal overfitting at extreme depths (DT) or inappropriate k values (KNN).

## ‚ñ∂Ô∏è How to Run
1. Clone the repo:
   ```bash
   git clone https://github.com/<your-username>/<this-repo>.git
   cd <this-repo>
